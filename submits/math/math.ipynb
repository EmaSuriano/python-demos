{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determinante\n",
    "\n",
    "Tal y como ya hemos visto en clase, la variedad de herramientas proporcionadas por el algebra lineal son cruciales para desarrollar y fundamentar las bases de una variedad de tecnicas relacionadas con el aprendizaje automatico. Con ella, podemos describir el proceso de propagacion hacia adelante en una red neuronal, identificar mınimos locales en funciones multivariables (crucial para el proceso de retropropagacion) o la descripcion y empleo de metodos de reduccion de la dimensionalidad, como el analisis de componentes principales (PCA), entre muchas otras aplicaciones.\n",
    "\n",
    "Cuando trabajamos en la practica dentro de este ambito, la cantidad de datos que manejamos puede ser muy grande, por lo que es especialmente importante emplear algoritmos eficientes y optimizados para reducir el coste computacional en la medida de lo posible. Por todo ello, el objetivo de este ejercicio es el de ilustrar las diferentes alternativas que pueden existir para realizar un proceso relacionado con el algebra lineal y el impacto que puede tener cada variante en terminos del coste computacional del mismo. En este caso en particular, y a modo de ilustracion, nos centraremos en el calculo del determinante de una matriz.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) [1 punto] Implementa una funcion, `determinante_recursivo`, que obtenga el determinante de una matriz cuadrada utilizando la definicion recursiva de Laplace.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data analysis libs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# utils libs\n",
    "import copy\n",
    "import random\n",
    "import math\n",
    "\n",
    "\n",
    "# graphical libs\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# typehint libs\n",
    "from typing import Callable\n",
    "from numpy.typing import NDArray\n",
    "\n",
    "# Avoid annoying warning for deprecations ...\n",
    "import warnings\n",
    "\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_square_matrix(n: int, n_range: tuple[int, int] = (0, 100)) -> list[list]:\n",
    "    \"\"\"generate random matrix of n size\n",
    "\n",
    "    Args:\n",
    "        n (int): amount of rows/columns\n",
    "        n_range (tuple[int, int], optional): range of numbers for each item in the matrix. Defaults to (0, 100).\n",
    "\n",
    "    Returns:\n",
    "        list[list]: generated matrix\n",
    "    \"\"\"\n",
    "    return [[random.randint(*n_range) for _ in range(n)] for _ in range(n)]\n",
    "\n",
    "\n",
    "def display_matrix(matrix: list[list]):\n",
    "    \"\"\"Display matrix in terminal nicely\n",
    "\n",
    "    Args:\n",
    "        matrix (list[list]): matrix that you want to display\n",
    "    \"\"\"\n",
    "    print(\"\")\n",
    "    for i in range(len(matrix)):\n",
    "        print(\" \".join([f\"{n:02}\" for n in matrix[i]]))\n",
    "    print(\"\")\n",
    "\n",
    "\n",
    "matrix = get_square_matrix(3)\n",
    "assert len(matrix) == 3 and len(matrix[0]) == 3\n",
    "\n",
    "display_matrix(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determinante_recursivo(matrix: list[list]) -> float:\n",
    "    \"\"\"get determinant of a matrix using Laplace recursive method\n",
    "\n",
    "    Args:\n",
    "        matrix (list[list]): squared matrix to obtain the determinant from\n",
    "\n",
    "    Raises:\n",
    "        Exception: in case the matrix is not squared\n",
    "\n",
    "    Returns:\n",
    "        float: value of the determinant\n",
    "    \"\"\"\n",
    "    if len(matrix) != len(matrix[0]):\n",
    "        raise Exception(\"Matriz no es cuadrada...\")\n",
    "\n",
    "    if len(matrix) == 2:\n",
    "        a, b = matrix[0]\n",
    "        c, d = matrix[1]\n",
    "        return a * d - b * c\n",
    "\n",
    "    res = 0\n",
    "    for i, n in enumerate(matrix[0]):\n",
    "        sub_matrix = [[el for j, el in enumerate(row) if j != i] for row in matrix[1:]]\n",
    "        res += n * (-1) ** i * determinante_recursivo(sub_matrix)\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "matrix = get_square_matrix(4)\n",
    "\n",
    "print(\"Matriz resultante:\")\n",
    "display_matrix(matrix)\n",
    "print(\"Valor del determinante:\", determinante_recursivo(matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) [0.5 puntos] Si A es una matriz cuadrada n×n y triangular (superior o inferior, es decir, con entradas nulas por debajo o por encima de la diagonal, respectivamente), ¿existe alguna forma de calcular de forma directa y sencilla su determinante? Justifıquese larespuesta.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_matrix_triangular(matrix: list[list]) -> bool:\n",
    "    \"\"\"checks if a matrix is triangular and squared\n",
    "\n",
    "    Args:\n",
    "        matrix (list[list]): matrix to check\n",
    "\n",
    "    Returns:\n",
    "        bool: if the matrix is triangular\n",
    "    \"\"\"\n",
    "    is_superior = True\n",
    "    is_inferior = True\n",
    "\n",
    "    for i in range(len(matrix)):\n",
    "        for j in range(len(matrix)):\n",
    "            if j > i and not math.isclose(matrix[i][j], 0, abs_tol=1e-12):\n",
    "                is_superior = False\n",
    "\n",
    "    for i in range(len(matrix)):\n",
    "        for j in range(len(matrix)):\n",
    "            if j < i and not math.isclose(matrix[i][j], 0, abs_tol=1e-12):\n",
    "                is_inferior = False\n",
    "\n",
    "    return is_superior or is_inferior\n",
    "\n",
    "\n",
    "def get_triangular_matrix(\n",
    "    n: int, n_range: tuple[int, int] = (0, 100), superior=True\n",
    ") -> list[list]:\n",
    "    \"\"\"generate a triangular matrix either superior or inferior\n",
    "\n",
    "    Args:\n",
    "        n (int): amount of rows/columns\n",
    "        n_range (tuple[int, int], optional): range of numbers for each item in the matrix. Defaults to (0, 100).\n",
    "        superior (bool, optional): if the resulting matrix should be superior or not. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        list[list]: triangular matrix\n",
    "    \"\"\"\n",
    "    matrix = get_square_matrix(n, n_range)\n",
    "\n",
    "    if superior:\n",
    "        for i in range(len(matrix)):\n",
    "            for j in range(len(matrix)):\n",
    "                if j > i:\n",
    "                    matrix[i][j] = 0\n",
    "    else:\n",
    "        for i in range(len(matrix)):\n",
    "            for j in range(len(matrix)):\n",
    "                if j < i:\n",
    "                    matrix[i][j] = 0\n",
    "\n",
    "    return matrix\n",
    "\n",
    "\n",
    "superior_matrix = get_triangular_matrix(4, superior=True)\n",
    "inferior_matrix = get_triangular_matrix(4, superior=True)\n",
    "\n",
    "print(\"Matriz Triangular superior:\")\n",
    "assert is_valid_matrix_triangular(superior_matrix)\n",
    "display_matrix(superior_matrix)\n",
    "\n",
    "\n",
    "print(\"Matriz Triangular inferior:\")\n",
    "assert is_valid_matrix_triangular(inferior_matrix)\n",
    "display_matrix(inferior_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determinante_matriz_triangular(matrix: list[list]) -> float:\n",
    "    \"\"\"calculate determinant of a matrix using only the diagonal of it\n",
    "    Args:\n",
    "        matrix (list[list]): squared and diagonal matrix to obtain the determinant from\n",
    "\n",
    "    Raises:\n",
    "        Exception: in case the matrix is not diagonal\n",
    "\n",
    "    Returns:\n",
    "        float: value of the determinant\n",
    "    \"\"\"\n",
    "    if not is_valid_matrix_triangular(matrix):\n",
    "        raise Exception(\"Matriz no es triangular (inferior o superior)\")\n",
    "\n",
    "    res = matrix[0][0]\n",
    "    for i in range(1, len(matrix)):\n",
    "        res *= matrix[i][i]\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "# generate two triangular matrixes, one inferior and another superior to run the assertions\n",
    "for superior in range(2):\n",
    "    triangular_matrix = get_triangular_matrix(3, superior=superior)\n",
    "\n",
    "    print(\"Matriz\", \"superior:\" if superior else \"inferior:\")\n",
    "    display_matrix(triangular_matrix)\n",
    "\n",
    "    det_tri = determinante_matriz_triangular(triangular_matrix)\n",
    "    det_rec = determinante_matriz_triangular(triangular_matrix)\n",
    "\n",
    "    assert det_tri == det_rec\n",
    "    print(\"Valor del determinante utlizando diagonal principal:\", det_tri)\n",
    "    print(\"Valor del determinante utlizando Laplace:\", det_rec)\n",
    "\n",
    "\n",
    "print(\n",
    "    \"\"\"\\nJustificacion:\n",
    "    \n",
    "    El determinante para una matrix triangular se puede calcular como la multiplicacion de los elementos de su diagonal.\n",
    "    Como se puede observar para las dos matrices triangulares (inferior o superior), el resultado del determinante mediante los dos metodos es el mismo.\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) [0.5 puntos] Determınese de forma justificada como alteran el determinante de una matriz n × n las dos operaciones elementales siguientes:\n",
    "\n",
    "- Intercambiar una fila (o columna) por otra fila (o columna).\n",
    "- Sumar a una fila (o columna) otra fila (o columna) multiplicada por un escalar α.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap_matrix_rows(matrix: list[list], rows: tuple[int, int]) -> list[list]:\n",
    "    \"\"\"swap rows of a matrix\n",
    "\n",
    "    Args:\n",
    "        matrix (list[list]): matrix\n",
    "        row1 (tuple[int, int]): rows to swap\n",
    "\n",
    "    Returns:\n",
    "        list[list]: matrix with the rows swapped\n",
    "    \"\"\"\n",
    "    # copy parameter matrix to avoid modifying parameters\n",
    "    matrix_copy = copy.deepcopy(matrix)\n",
    "\n",
    "    matrix_copy[rows[0]], matrix_copy[rows[1]] = (\n",
    "        matrix_copy[rows[1]],\n",
    "        matrix_copy[rows[0]],\n",
    "    )\n",
    "\n",
    "    return matrix_copy\n",
    "\n",
    "\n",
    "def swap_matrix_columns(matrix: list[list], cols: tuple[int, int]) -> list[list]:\n",
    "    \"\"\"swap columns of a matrix\n",
    "\n",
    "    Args:\n",
    "        matrix (list[list]): matrix\n",
    "        cols (tuple[int, int]): columns to swap\n",
    "\n",
    "    Returns:\n",
    "        list[list]: matrix with the rows swapped\n",
    "    \"\"\"\n",
    "    # copy parameter matrix to avoid modifying parameters\n",
    "    matrix_copy = copy.deepcopy(matrix)\n",
    "\n",
    "    for row in matrix_copy:\n",
    "        row[cols[0]], row[cols[1]] = row[cols[1]], row[cols[0]]\n",
    "\n",
    "    return matrix_copy\n",
    "\n",
    "\n",
    "matrix = [[1, 2], [3, 4]]\n",
    "\n",
    "assert swap_matrix_rows(matrix, (0, 1)) == [[3, 4], [1, 2]]\n",
    "assert swap_matrix_columns(matrix, (0, 1)) == [[2, 1], [4, 3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_matrix = get_square_matrix(3)\n",
    "\n",
    "print(\"Matriz original: \")\n",
    "display_matrix(original_matrix)\n",
    "print(\"Valor del determinante:\", determinante_recursivo(original_matrix))\n",
    "\n",
    "matrix_with_exchange_row = swap_matrix_rows(original_matrix, (0, 1))\n",
    "print(\"Matriz con la primera fila intercambiada con la segunda: \")\n",
    "display_matrix(matrix_with_exchange_row)\n",
    "print(\"Valor del determinante:\", determinante_recursivo(matrix_with_exchange_row))\n",
    "\n",
    "\n",
    "matrix_with_exchange_column = swap_matrix_columns(original_matrix, (0, 1))\n",
    "print(\"Matriz con la primera columna intercambiada con la segunda: \")\n",
    "display_matrix(matrix_with_exchange_column)\n",
    "print(\"Valor del determinante:\", determinante_recursivo(matrix_with_exchange_column))\n",
    "\n",
    "print(\n",
    "    \"\"\"\\nJustificacion:\n",
    "    \n",
    "    Al intercambiar una columna o una fila de una matriz, el determinante sera igual al valor del determinante original pero multiplicado por -1.\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_rows_in_matrix(\n",
    "    matrix: list[list], rows: tuple[int, int], multiplier: float\n",
    ") -> list[list]:\n",
    "    \"\"\"sum one row to another multiplied by a number\n",
    "\n",
    "    Args:\n",
    "        matrix (list[list]): given matrix\n",
    "        rows (tuple[int, int]): rows to apply the operation\n",
    "        multiplier (float): value for the multiplication\n",
    "\n",
    "    Returns:\n",
    "        list[list]: resulting matrix\n",
    "    \"\"\"\n",
    "    # copy parameter matrix to avoid modifying parameters\n",
    "    matrix_copy = copy.deepcopy(matrix)\n",
    "\n",
    "    for i in range(len(matrix_copy)):\n",
    "        matrix_copy[rows[0]][i] += matrix_copy[rows[1]][i] * multiplier\n",
    "\n",
    "    return matrix_copy\n",
    "\n",
    "\n",
    "def sum_columns_in_matrix(\n",
    "    matrix: list[list], cols: tuple[int, int], multiplier: float\n",
    ") -> list[list]:\n",
    "    \"\"\"sum one column to another multiplied by a number\n",
    "\n",
    "    Args:\n",
    "        matrix (list[list]): given matrix\n",
    "        cols (tuple[int, int]): cols to apply the operation\n",
    "        multiplier (float): value for the multiplication\n",
    "\n",
    "    Returns:\n",
    "        list[list]: resulting matrix\n",
    "    \"\"\"\n",
    "    # copy parameter matrix to avoid modifying parameters\n",
    "    matrix_copy = copy.deepcopy(matrix)\n",
    "\n",
    "    for i in range(len(matrix_copy)):\n",
    "        matrix_copy[i][cols[0]] += matrix_copy[i][cols[1]] * multiplier\n",
    "\n",
    "    return matrix_copy\n",
    "\n",
    "\n",
    "matrix = [[1, 2], [3, 4]]\n",
    "\n",
    "assert sum_rows_in_matrix(matrix, (0, 1), 2) == [[7, 10], [3, 4]]\n",
    "assert sum_columns_in_matrix(matrix, (0, 1), 2) == [[5, 2], [11, 4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_matrix = get_square_matrix(3)\n",
    "\n",
    "print(\"Matriz original: \")\n",
    "display_matrix(original_matrix)\n",
    "print(\"Valor del determinante:\", determinante_recursivo(original_matrix))\n",
    "\n",
    "\n",
    "matrix_with_multiplied_rows = sum_rows_in_matrix(original_matrix, (0, 1), 2)\n",
    "print(\"Matriz con la segunda fila multiplicada por 2 y sumada a la primera fila:\")\n",
    "display_matrix(matrix_with_multiplied_rows)\n",
    "print(\"Valor del determinante:\", determinante_recursivo(matrix_with_multiplied_rows))\n",
    "\n",
    "\n",
    "matrix_with_multiplied_column = sum_columns_in_matrix(original_matrix, (0, 1), 2)\n",
    "print(\"Matriz con la segunda columna multiplicada por 2 y sumada a la primera columna:\")\n",
    "display_matrix(matrix_with_multiplied_column)\n",
    "print(\"Valor del determinante:\", determinante_recursivo(matrix_with_multiplied_column))\n",
    "\n",
    "\n",
    "print(\n",
    "    \"\"\"\\nJustificacion:\n",
    "    \n",
    "    Al sumar a una fila (o columna) otra fila (o columna) multiplicada por un escalar, el valor del determinante no se ve alterado\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) [1 punto] Investiga sobre el metodo de eliminacion de Gauss con pivoteo parcial e implementalo para escalonar una matriz (es decir, convertirla en una matriz triangular inferior) a partir de las operaciones elementales descritas en el apartado anterior.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_elimination(matrix: list[list]) -> list[list]:\n",
    "    \"\"\"perform the gaussian elimination method for a given matrix\n",
    "\n",
    "    Args:\n",
    "        matrix (list[list]): _description_\n",
    "\n",
    "    Returns:\n",
    "        list[list]: _description_\n",
    "    \"\"\"\n",
    "    matrix_copy = copy.deepcopy(matrix)\n",
    "\n",
    "    for i in range(len(matrix_copy)):\n",
    "        # find the proper row pivot to avoid zero division and rounded errors\n",
    "        for j in range(i + 1, len(matrix_copy)):\n",
    "            if matrix_copy[i][i] < matrix_copy[j][i]:\n",
    "                matrix_copy = swap_matrix_rows(matrix_copy, (i, j))\n",
    "\n",
    "        # apply rows operations in order to ensure triangularly of the matrix\n",
    "        for j in range(i + 1, len(matrix_copy)):\n",
    "            multiplier = matrix_copy[j][i] / matrix_copy[i][i]\n",
    "            matrix_copy = sum_rows_in_matrix(matrix_copy, (j, i), -multiplier)\n",
    "\n",
    "    return matrix_copy\n",
    "\n",
    "\n",
    "# matrix = get_square_matrix(3)\n",
    "matrix = [[1, 2, 3], [2, 4, 6], [1, 5, 6]]\n",
    "print(\"Original matrix:\")\n",
    "display_matrix(matrix)\n",
    "\n",
    "matrix_gaussian_elimination = gaussian_elimination(matrix)\n",
    "print(\"Gaussian elimination matrix:\")\n",
    "display_matrix(matrix_gaussian_elimination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) [0.5 puntos] ¿Como se podrıa calcular el determinante de una matriz haciendo beneficio de la estrategia anterior y del efecto de aplicar las operaciones elementales pertinentes? Implementa una nueva funcion, `determinante_gauss`, que calcule el determinante de una matriz utilizando eliminacion gaussiana.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determinante_gauss(matrix: list[list]) -> float:\n",
    "    \"\"\"Get determinant of a matrix first by using the Gauss method to make the matrix triangular and then obtain the determinant of a triangular matrix\n",
    "\n",
    "    Args:\n",
    "        matrix (list[list]): initial matrix\n",
    "\n",
    "    Returns:\n",
    "        float: value of the determinant\n",
    "    \"\"\"\n",
    "    matrix_gaussian_elimination = gaussian_elimination(matrix)\n",
    "    return determinante_matriz_triangular(matrix_gaussian_elimination)\n",
    "\n",
    "\n",
    "matrix = get_square_matrix(3)\n",
    "det_matrix = determinante_recursivo(matrix)\n",
    "det_matrix_gaussian_triangular = determinante_gauss(matrix)\n",
    "\n",
    "print(\"Matriz original:\")\n",
    "display_matrix(matrix)\n",
    "\n",
    "print(\"Valor del determinante utilizando Laplace:\", det_matrix)\n",
    "print(\n",
    "    \"Valor del determinante utilizando Gauss y Diagonal principal:\",\n",
    "    det_matrix_gaussian_triangular,\n",
    ")\n",
    "\n",
    "\n",
    "print(\n",
    "    \"\"\"\\nJustificacion:\n",
    "    \n",
    "    Una vez hecho la diagonalizacion de una matrix utilizando Gauss, se puede obtener facilmente el determinante utilizando el metodo para matrices triangulares.\n",
    "    Donde el determinante se puede calcular como la multiplicacion de los elementos de su diagonal.\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f ) [0.5 puntos] Obten la complejidad computacional asociada al calculo del determinante con la definicion recursiva y con el metodo de eliminacion de Gauss con pivoteo parcial.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"\"\"Complejidad computacional para el calculo del determinante:\n",
    "\n",
    "    - Definicion recursiva (Laplace): O(n!) por su propiedad recursiva\n",
    "    - Definicion recursiva (Laplace): O(n**3) son 3 for anidados\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g) [1 punto] Utilizando `numpy.random.rand`, genera matrices cuadradas aleatorias de la forma $An ∈ R n×n$, para $2 ≤ n ≤ 10 $\n",
    "\n",
    "Confecciona una tabla comparativa del tiempo de ejecucion asociado a cada una de las variantes siguientes, interpretando los resultados:\n",
    "\n",
    "- Utilizando determinante recursivo.\n",
    "- Empleando determinante gauss.\n",
    "- Haciendo uso de la funcion preprogramada numpy.linalg.det.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import timeit\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "data = []\n",
    "\n",
    "input_range = range(2, 11)\n",
    "input_sizes = [np.random.rand(n, n).tolist() for n in input_range]\n",
    "\n",
    "for n in input_sizes:\n",
    "    recur_time = timeit(lambda: determinante_recursivo(n), number=1)\n",
    "    gauss_time = timeit(lambda: determinante_gauss(n), number=1)\n",
    "    numpy_time = timeit(lambda: np.linalg.det(n), number=1)\n",
    "\n",
    "    data.extend(\n",
    "        [\n",
    "            [\"Recursive\", len(n), recur_time],\n",
    "            [\"Gauss\", len(n), gauss_time],\n",
    "            [\"Numpy\", len(n), numpy_time],\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data, columns=[\"Method\", \"n\", \"Time\"])\n",
    "\n",
    "fig = px.line(\n",
    "    df,\n",
    "    x=\"n\",\n",
    "    y=\"Time\",\n",
    "    color=\"Method\",\n",
    "    markers=True,\n",
    "    title=\"Time to calculate matrix determinant\",\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descenso del gradiente\n",
    "\n",
    "En este ejercicio trabajaremos con el metodo de descenso de gradiente, el cual constituye otra herramienta crucial, en esta ocasion de la rama del calculo, para el proceso de retropropagacion asociado al entrenamiento de una red neuronal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) [1 punto] Programese en Python el metodo de descenso de gradiente para funciones de $n$ variables. La funcion debera tener como parametros de entradas:\n",
    "\n",
    "- El gradiente de la funcion que se desea minimizar $∇f$ (puede venir dada como otra funcion previamente implementada, `grad_f`, con entrada un vector, representando el punto donde se quiere calcular el gradiente, y salida otro vector, representando el gradiente de $f$ en dicho punto).\n",
    "- Un valor inicial $x0 ∈ Rn$ (almacenado en un vector de $n$ componentes).\n",
    "- El ratio de aprendizaje $γ$ (que se asume constante para cada iteracion).\n",
    "- Un parametro de tolerancia `tol` (con el que finalizar el proceso cuando $∥∇f(x)∥2$ < tol).\n",
    "- Un numero maximo de iteraciones `maxit` (con el fin de evitar ejecuciones indefinidas en caso de divergencia o convergencia muy lenta).\n",
    "\n",
    "La salida de la funcion debera ser la aproximacion del $x$ que cumple $f′(x) ≈ 0$, correspondiente a la ultima iteracion realizada en el metodo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(\n",
    "    grad_f: Callable,\n",
    "    initial_point: NDArray,\n",
    "    learning_rate=0.01,\n",
    "    maxit=1000,\n",
    "    tol=1e-6,\n",
    ") -> list[NDArray]:\n",
    "    \"\"\"get minimum point of a function using method of gradient descent with derivate\n",
    "\n",
    "    Args:\n",
    "        grad_f (Callable): derivate of the function\n",
    "        initial_point (NDArray): start point to start looking for the minimum point\n",
    "        learning_rate (float, optional): learning rate to move the point on each iteration. Defaults to 0.01.\n",
    "        maxit (int, optional): numbers of max iterations to run. Defaults to 1000.\n",
    "        tol (float, optional): tolerance value to finish the algorithm in case we found point of convergence. Defaults to 1e-6.\n",
    "\n",
    "    Returns:\n",
    "        list[NDArray]: history of the points inside the algorithm of gradient descent\n",
    "    \"\"\"\n",
    "    point = np.array(initial_point)\n",
    "    history = np.array([point])\n",
    "\n",
    "    for _ in range(maxit):\n",
    "        # get gradient from the derivate function\n",
    "        grad = np.array(grad_f(*point))\n",
    "\n",
    "        # Check for point convergence\n",
    "        if np.linalg.norm(grad) < tol:\n",
    "            break\n",
    "\n",
    "        # get new point for the next iteration\n",
    "        point -= grad * learning_rate\n",
    "\n",
    "        # save it in history\n",
    "        history = np.concatenate((history, [point]), axis=0)\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_function_2d_with_gradient(\n",
    "    f: Callable, graph_range: tuple[float, float], descent_history: NDArray\n",
    "):\n",
    "    \"\"\"Create plot using plotly to represent a gradient descent result of function\n",
    "\n",
    "    Args:\n",
    "        f (Callable): function to render\n",
    "        graph_range (tuple[float, float]): range to draw the function\n",
    "        descent_history (NDArray): history of the gradient descent algorithm\n",
    "    \"\"\"\n",
    "    # Vectorize function in order to be possible to support numpy array operations\n",
    "    f_vector = np.vectorize(f)\n",
    "\n",
    "    x = np.linspace(*graph_range, 100)\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=x, y=f_vector(x), mode=\"lines\", name=\"Function\"))\n",
    "\n",
    "    descent_df = pd.DataFrame(\n",
    "        [(*p, f_vector(*p)) for p in descent_history], columns=[\"x\", \"y\"]\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=descent_df[\"x\"],\n",
    "                y=descent_df[\"y\"],\n",
    "                mode=\"markers\",\n",
    "                name=\"Gradient\",\n",
    "            )\n",
    "        )\n",
    "    except OverflowError:\n",
    "        print(\"Cannot draw gradient history due to Overflow Error\")\n",
    "\n",
    "    fig.update_layout(title=f\"Punto minimo encontrado en {descent_history[-1]}\")\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Sea la funcion $f : R → R$ dada por: $$f(x) = 3x^4 + 4x^3 − 12x^2 + 7$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x: float) -> float:\n",
    "    return 3 * (x**4) + 4 * (x**3) - 12 * x**2 + 7\n",
    "\n",
    "\n",
    "def df(x: float) -> float:\n",
    "    return 12 * (x**3) + 12 * (x**2) - 12 * x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I. [0.5 puntos] Aplica el metodo sobre $f(x)$ con $x0$= 3 $γ$= 0.001, `tol`=1e-12, `maxit`=1e5.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descent_history = gradient_descent(\n",
    "    df,\n",
    "    initial_point=[float(3)],\n",
    "    learning_rate=0.001,\n",
    "    tol=1e-12,\n",
    "    maxit=int(1e5),\n",
    ")\n",
    "\n",
    "\n",
    "draw_function_2d_with_gradient(f, (-3, 3), descent_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "II. [0.5 puntos] Aplica de nuevo el metodo sobre $f(x)$ con $x0$ = 3, $γ$ = 0.01, `tol`=1e-12, `maxit`=1e5.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descent_history = gradient_descent(\n",
    "    df,\n",
    "    initial_point=[float(3)],\n",
    "    learning_rate=0.01,\n",
    "    tol=1e-12,\n",
    "    maxit=int(1e5),\n",
    ")\n",
    "\n",
    "draw_function_2d_with_gradient(f, (-3, 3), descent_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "III. [0.5 puntos] Contrasta e interpreta los dos resultados obtenidos en los apartados anteriores y comparalos con los mınimos locales obtenidos analıticamente. ¿Que influencia puede llegar a tener la eleccion del ratio de aprendizaje $γ$?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"\"\"Justificacion:\n",
    "      La tasa de aprendizaje (y) tiene una influencia significativa en el comportamiento del descenso del gradiente:\n",
    "        - Si es demasiado alta puede causar oscilaciones o divergencia.\n",
    "        - Si es demasiado baja puede resultar en una convergencia muy lenta.\n",
    "        - Dependiendo del punto inicial, puede converger a diferentes minimos locales en funciones no convexas.\n",
    "      \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IV. [0.5 puntos] Aplica nuevamente el metodo sobre $f(x)$ con $x0$ = 3, $γ$ = 0.1, `tol`=1e-12, `maxit`=1e5. Interpreta el resultado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descent_history = gradient_descent(\n",
    "    df,\n",
    "    initial_point=[float(3)],\n",
    "    learning_rate=0.1,\n",
    "    tol=1e-12,\n",
    "    maxit=int(1e5),\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"\"\"Justificacion:\n",
    "      \n",
    "      Al tener un ratio de aprendizaje tan grande el algoritmo no puedo llegar a encontrar un punto de divergencia y por lo tanto tiende al infinito\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "draw_function_2d_with_gradient(f, (-3, 3), descent_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "V. [0.5 puntos] Finalmente, aplica el metodo sobre $f(x)$ con $x0$ = 0, $γ$ = 0.001, `tol`=1e-12, `maxit`=1e5. Interpreta el resultado y comparalo con el estudio analıtico de $f$. ¿Se trata de un resultado deseable? ¿Por que? ¿A que se debe este fenomeno?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descent_history = gradient_descent(\n",
    "    df,\n",
    "    initial_point=[float(0)],\n",
    "    learning_rate=0.0001,\n",
    "    tol=1e-12,\n",
    "    maxit=int(1e5),\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"\"\"Justificacion:\n",
    "      \n",
    "      En el punto inicial seleccionado no es posible convergir a ningun otro punto, dado que como se puede observar la funcion no cuenta con una pendiente definida en ese punto. \n",
    "      Es decir la derivada de la funcion en este punto es 0, y por lo tanto el algoritmo para.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "draw_function_2d_with_gradient(f, (-3, 3), descent_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Sea la funcion $g : R^2 -> R^2$ dada por $$g(x, y) = x^2 + y^3 + 3xy + 1$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x: float, y: float) -> float:\n",
    "    return x**2 + y**3 + 3 * x * y + 1\n",
    "\n",
    "\n",
    "def df(x: float, y: float) -> list:\n",
    "    return [2 * x + 3 * y, 3 * y**2 + 3 * x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_function_3d_with_gradient(\n",
    "    f: Callable, graph_range: tuple[float, float], descent_history: NDArray\n",
    "):\n",
    "    \"\"\"Create plot using plotly to represent a gradient descent result of function\n",
    "\n",
    "    Args:\n",
    "        f (Callable): function to render\n",
    "        graph_range (tuple[float, float]): range to draw the function\n",
    "        descent_history (NDArray): history of the gradient descent algorithm\n",
    "    \"\"\"\n",
    "    # Vectorize function in order to be possible to support numpy array operations\n",
    "    f_vector = np.vectorize(f)\n",
    "\n",
    "    # Create a grid of x and y values\n",
    "    x, y = np.meshgrid(np.linspace(*graph_range, 100), np.linspace(*graph_range, 100))\n",
    "    z = f_vector(x, y)\n",
    "\n",
    "    # Create the plot\n",
    "    fig = go.Figure(data=[go.Surface(z=z, x=x, y=y, opacity=0.7)])\n",
    "\n",
    "    # convert history to pandas df\n",
    "    descent_df = pd.DataFrame(\n",
    "        [(*p, f_vector(*p)) for p in descent_history], columns=[\"x\", \"y\", \"z\"]\n",
    "    )\n",
    "\n",
    "    # mark start and end point of the gradient history\n",
    "    points_df = pd.concat([descent_df.iloc[[0]], descent_df.iloc[[-1]]])\n",
    "    fig.add_traces(\n",
    "        go.Scatter3d(\n",
    "            x=points_df[\"x\"],\n",
    "            y=points_df[\"y\"],\n",
    "            z=points_df[\"z\"],\n",
    "            mode=\"markers+text\",\n",
    "            text=[\"Start\", \"End\"],\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # add gradient line\n",
    "    fig.add_traces(\n",
    "        px.line_3d(\n",
    "            descent_df, x=\"x\", y=\"y\", z=\"z\", color_discrete_sequence=[\"white\"]\n",
    "        ).data\n",
    "    )\n",
    "\n",
    "    fig.update_layout(title=f\"Punto minimo encontrado en {descent_history[-1]}\")\n",
    "\n",
    "    # Show the plot\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I. [0.5 puntos] Aplıquese el metodo sobre $g(x, y)$ con $x0$ = (−1, 1), $γ$ = 0.01, `tol`=1e-12, `maxit`=1e5.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descent_history = gradient_descent(\n",
    "    df,\n",
    "    initial_point=[float(-1), float(1)],\n",
    "    learning_rate=0.01,\n",
    "    tol=1e-12,\n",
    "    maxit=int(1e5),\n",
    ")\n",
    "\n",
    "draw_function_3d_with_gradient(f, (-5, 5), descent_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "II [0.5 puntos] ¿Que ocurre si ahora partimos de $x0 = (0, 0)$? ¿Se obtiene un resultado deseable?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descent_history = gradient_descent(\n",
    "    df,\n",
    "    initial_point=[float(0), float(0)],\n",
    "    learning_rate=0.01,\n",
    "    tol=1e-12,\n",
    "    maxit=int(1e5),\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"\"\"Justificacion:\n",
    "      \n",
    "      En el punto inicial seleccionado no es posible convergir a ningun otro punto, dado que como se puede observar la funcion no cuenta con una pendiente definida en ese punto. \n",
    "      Es decir la derivada de la funcion en este punto es 0, y por lo tanto el algoritmo para.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "draw_function_3d_with_gradient(f, (-5, 5), descent_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "III. [0.5 puntos] Realicese el estudio analıtico de la funcion y utilıcese para explicar y contrastar los resultados obtenidos en los dos apartados anteriores.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
